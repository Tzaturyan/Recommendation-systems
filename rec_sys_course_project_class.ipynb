{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2528788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightautoml in c:\\users\\1\\anaconda3\\lib\\site-packages (0.3.7.3)\n",
      "Requirement already satisfied: autowoe>=1.2 in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (1.3.2)\n",
      "Requirement already satisfied: catboost>=0.26.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (1.2)\n",
      "Requirement already satisfied: cmaes in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (0.9.1)\n",
      "Requirement already satisfied: holidays in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (0.28)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (2.11.3)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: joblib in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (1.1.0)\n",
      "Requirement already satisfied: json2html in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (1.3.0)\n",
      "Requirement already satisfied: lightgbm<=3.2.1,>=2.3 in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (3.2.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (2.7.1)\n",
      "Requirement already satisfied: optuna in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (3.2.0)\n",
      "Requirement already satisfied: pandas<=1.4.3 in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (1.4.2)\n",
      "Requirement already satisfied: poetry-core<2.0.0,>=1.0.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (1.6.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.1 -> 23.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (1.0.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (0.11.2)\n",
      "Requirement already satisfied: torch<1.9 in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (1.8.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (0.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightautoml) (4.64.0)\n",
      "Requirement already satisfied: StrEnum<0.5.0,>=0.4.7 in c:\\users\\1\\anaconda3\\lib\\site-packages (from autowoe>=1.2->lightautoml) (0.4.15)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\1\\appdata\\roaming\\python\\python39\\site-packages (from autowoe>=1.2->lightautoml) (3.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\1\\anaconda3\\lib\\site-packages (from autowoe>=1.2->lightautoml) (1.21.0)\n",
      "Requirement already satisfied: pytest in c:\\users\\1\\anaconda3\\lib\\site-packages (from autowoe>=1.2->lightautoml) (7.1.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\1\\anaconda3\\lib\\site-packages (from autowoe>=1.2->lightautoml) (2021.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\1\\anaconda3\\lib\\site-packages (from autowoe>=1.2->lightautoml) (1.7.3)\n",
      "Requirement already satisfied: sphinx in c:\\users\\1\\anaconda3\\lib\\site-packages (from autowoe>=1.2->lightautoml) (4.4.0)\n",
      "Requirement already satisfied: sphinx-rtd-theme in c:\\users\\1\\anaconda3\\lib\\site-packages (from autowoe>=1.2->lightautoml) (1.2.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\1\\anaconda3\\lib\\site-packages (from catboost>=0.26.1->lightautoml) (0.20.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\1\\anaconda3\\lib\\site-packages (from catboost>=0.26.1->lightautoml) (5.6.0)\n",
      "Requirement already satisfied: six in c:\\users\\1\\anaconda3\\lib\\site-packages (from catboost>=0.26.1->lightautoml) (1.16.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\1\\anaconda3\\lib\\site-packages (from lightgbm<=3.2.1,>=2.3->lightautoml) (0.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from pandas<=1.4.3->lightautoml) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->lightautoml) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\1\\anaconda3\\lib\\site-packages (from torch<1.9->lightautoml) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\1\\anaconda3\\lib\\site-packages (from tqdm->lightautoml) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\1\\anaconda3\\lib\\site-packages (from jinja2->lightautoml) (2.0.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from optuna->lightautoml) (1.11.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\1\\anaconda3\\lib\\site-packages (from optuna->lightautoml) (6.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from optuna->lightautoml) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from optuna->lightautoml) (1.4.32)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from torchvision->lightautoml) (9.0.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\1\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna->lightautoml) (1.2.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\1\\anaconda3\\lib\\site-packages (from matplotlib->autowoe>=1.2->lightautoml) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from matplotlib->autowoe>=1.2->lightautoml) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from matplotlib->autowoe>=1.2->lightautoml) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna->lightautoml) (2.0.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from plotly->catboost>=0.26.1->lightautoml) (8.0.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from pytest->autowoe>=1.2->lightautoml) (21.4.0)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\1\\anaconda3\\lib\\site-packages (from pytest->autowoe>=1.2->lightautoml) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\1\\anaconda3\\lib\\site-packages (from pytest->autowoe>=1.2->lightautoml) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\1\\anaconda3\\lib\\site-packages (from pytest->autowoe>=1.2->lightautoml) (1.11.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from pytest->autowoe>=1.2->lightautoml) (1.2.2)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from pytest->autowoe>=1.2->lightautoml) (1.4.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (1.0.3)\n",
      "Requirement already satisfied: Pygments>=2.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.11.2)\n",
      "Requirement already satisfied: docutils<0.18,>=0.14 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (0.17.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.2.0)\n",
      "Requirement already satisfied: babel>=1.3 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.9.1)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (0.7.12)\n",
      "Requirement already satisfied: imagesize in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (1.3.0)\n",
      "Requirement already satisfied: requests>=2.5.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.27.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx->autowoe>=1.2->lightautoml) (4.11.3)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in c:\\users\\1\\anaconda3\\lib\\site-packages (from sphinx-rtd-theme->autowoe>=1.2->lightautoml) (4.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\1\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->sphinx->autowoe>=1.2->lightautoml) (3.7.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx->autowoe>=1.2->lightautoml) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx->autowoe>=1.2->lightautoml) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx->autowoe>=1.2->lightautoml) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\1\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx->autowoe>=1.2->lightautoml) (3.3)\n"
     ]
    }
   ],
   "source": [
    "pip install -U lightautoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a1511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Модель второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm  as lgb \n",
    "import catboost as catb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d071ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.tasks.common_metric import mean_quantile_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6854dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended_list, bought_list, k=5):\n",
    "    \n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list)\n",
    "    # print(len(bought_list))\n",
    "    # print(len(recommended_list))\n",
    "    bought_list = bought_list  # Тут нет [:k] !!\n",
    "    recommended_list = recommended_list[:k]\n",
    "    \n",
    "    flags = np.isin(bought_list, recommended_list)\n",
    "    # print(len(flags))\n",
    "    precision = flags.sum() / len(recommended_list)\n",
    "    \n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c801bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(recommended_list, bought_list, k=5):\n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list)[:k]\n",
    "    \n",
    "    flags = np.isin(bought_list, recommended_list)\n",
    "    \n",
    "    recall = flags.sum() / len(bought_list)\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dfb699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefilter_items(data, item_features, drop_categories=[],take_n_popular=5000):\n",
    "    # 1. Уберем товары, которые не продавались за последние 12 месяцев\n",
    "    data = data.loc[~(data['week_no'] < data['week_no'].max() - 12)]\n",
    "\n",
    "    # 2. Уберем не интересные для рекоммендаций категории (department)\n",
    "    not_important_goods = item_features.loc[(item_features['department'].isin(drop_categories)), 'item_id'].tolist()\n",
    "    data = data.loc[(~data['item_id'].isin(not_important_goods))]\n",
    "\n",
    "    # 3. Уберем слишком дешевые товары (на них не заработаем). Товары, со средней ценой < 1$\n",
    "    data.drop(data[data['sales_value'] < 1].index, axis=0, inplace=True)\n",
    "\n",
    "    # 4. Уберем слишком дорогие товары. Товары со средней ценой > 30$\n",
    "    data.drop(data[data['sales_value'] > 30].index, axis=0, inplace=True)\n",
    "\n",
    "    # 5. Уберем самые популярные товары (их и так купят)\n",
    "    popularity = data.groupby('item_id')['user_id'].nunique().reset_index() / data['user_id'].nunique()\n",
    "    popularity.rename(columns={'user_id': 'share_unique_users'}, inplace=True)\n",
    "\n",
    "    top_popular = popularity[popularity['share_unique_users'] > 0.8].item_id.tolist()\n",
    "    data = data.loc[(~data['item_id'].isin(top_popular))]\n",
    "    # data = data.loc[(~data['item_id'].isin(not_important_goods))]\n",
    "    #\n",
    "    # # 6. Уберем самые НЕ популярные товары (их и так НЕ купят)\n",
    "    top_notpopular = popularity[popularity['share_unique_users'] < 0.01].item_id.tolist()\n",
    "    data = data.loc[(~data['item_id'].isin(top_notpopular))]\n",
    "    # result = data\n",
    "\t\n",
    "    # Возьмем топ по популярности\n",
    "    popularity = data.groupby('item_id')['quantity'].sum().reset_index()\n",
    "    popularity.rename(columns={'quantity': 'n_sold'}, inplace=True)\n",
    "\n",
    "    top = popularity.sort_values('n_sold', ascending=False).head(take_n_popular).item_id.tolist()\t\n",
    "    \n",
    "    # Заведем фиктивный item_id (если юзер покупал товары из топ-5000, то он \"купил\" такой товар)\n",
    "    data.loc[~data['item_id'].isin(top), 'item_id'] = 999999\n",
    "    \n",
    "    # ...\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23cade89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postfilter_items(recommendations, item_features, N=5):\n",
    "    \"\"\"Пост-фильтрация товаров\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    recommendations: list\n",
    "        Ранжированный список item_id для рекомендаций\n",
    "    item_info: pd.DataFrame\n",
    "        Датафрейм с информацией о товарах\n",
    "    \"\"\"\n",
    "    \n",
    "    # Уникальность\n",
    "#     recommendations = list(set(recommendations)) - неверно! так теряется порядок\n",
    "    unique_recommendations = []\n",
    "    [unique_recommendations.append(item) for item in recommendations if item not in unique_recommendations]\n",
    "    \n",
    "    # Разные категории\n",
    "    categories_used = []\n",
    "    final_recommendations = []\n",
    "    \n",
    "    CATEGORY_NAME = 'sub_commodity_desc'\n",
    "    for item in unique_recommendations:\n",
    "        category = item_features.loc[item_features['item_id'] == item, CATEGORY_NAME].values[0]\n",
    "        \n",
    "        if category not in categories_used:\n",
    "            final_recommendations.append(item)\n",
    "            \n",
    "        unique_recommendations.remove(item)\n",
    "        categories_used.append(category)\n",
    "    \n",
    "    # Для каждого юзера 5 рекомендаций (иногда модели могут возвращать < 5)\n",
    "    n_rec = len(final_recommendations)\n",
    "    if n_rec < N:\n",
    "        final_recommendations.extend(unique_recommendations[:N - n_rec])  # (!) это не совсем верно\n",
    "    else:\n",
    "        final_recommendations = final_recommendations[:N]\n",
    "        \n",
    "    # 2 новых товара (юзер никогда не покупал)\n",
    "    # your_code\n",
    "    \n",
    "    # 1 дорогой товар, > 7 долларов\n",
    "    # your_code\n",
    "    \n",
    "    assert len(final_recommendations) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "    return final_recommendations\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "def get_similar_item(model,  itemid_to_id, id_to_itemid, x):\n",
    "    id = itemid_to_id[x]\n",
    "    recs = model.similar_items(id, N=2)\n",
    "    top_rec = recs[1][0]\n",
    "    return id_to_itemid[top_rec]\n",
    "\n",
    "\n",
    "def get_similar_items_recommendation(user, data, itemid_to_id, id_to_itemid,  model, N=5):\n",
    "    \"\"\"Рекомендуем товары, похожие на топ-N купленных юзером товаров\"\"\"\n",
    "\n",
    "    top_purchases = data.groupby(['user_id', 'item_id'])['quantity'].count().reset_index()\n",
    "    top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
    "    top_purchases = top_purchases[top_purchases['item_id'] != 999999]\n",
    "\n",
    "    top_users_purchases = top_purchases[top_purchases['user_id'] == user].head(N)\n",
    "    res = top_users_purchases['item_id'].apply(lambda x: get_similar_item(model, itemid_to_id=itemid_to_id, id_to_itemid=id_to_itemid, x=x)).tolist()\n",
    "    return res\n",
    "\n",
    "def fit_own_recomender(user_item_matrix):\n",
    "    own = ItemItemRecommender(K=1, num_threads=4) # K - кол-во билжайших соседей\n",
    "    own.fit(csr_matrix(user_item_matrix).T.tocsr(), show_progress=False)\n",
    "    return own\n",
    "\n",
    "def get_own_recommendations(own, userid, user_item_matrix, N):\n",
    "    recs = own.recommend(userid=userid, \n",
    "                        user_items=csr_matrix(user_item_matrix).tocsr(),   # на вход user-item matrix\n",
    "                        N=N, \n",
    "                        filter_already_liked_items=False, \n",
    "                        filter_items=None, \n",
    "                        recalculate_user=False)\n",
    "    return recs\n",
    "\n",
    "def get_similar_users_recommendation(userid, userid_to_id, id_to_userid, user_item_matrix, model, N=5):\n",
    "    \"\"\"Рекомендуем топ-N товаров, среди купленных похожими юзерами\"\"\"\n",
    "    res = []\n",
    "\n",
    "    # Находим топ-N похожих пользователей\n",
    "    similar_users = model.similar_users(userid_to_id[userid], N=N+1) # user + N его друзей.\n",
    "    similar_users = [rec[0] for rec in similar_users]\n",
    "    similar_users = similar_users[1:]   # удалим юзера из запроса\n",
    " \n",
    "    own = fit_own_recomender(user_item_matrix)\n",
    " \n",
    "    for user in similar_users:\n",
    "        userid = id_to_userid[user] #own recommender works with user_ids\n",
    "        res.extend(get_own_recommendations(own, userid, user_item_matrix, N=1))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6f940f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_recommendation(data, n=5):\n",
    "    \"\"\"Топ-n популярных товаров\"\"\"\n",
    "    popular = data.groupby('item_id')['sales_value'].sum().reset_index()\n",
    "    popular.sort_values('sales_value', ascending=False, inplace=True)\n",
    "    recs = popular.head(n).item_id\n",
    "    return recs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620b5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_encoder(data,feature_names):\n",
    "    for feature_name in feature_names:\n",
    "        freq_encoder = data[feature_name].value_counts(normalize=True)\n",
    "        data[feature_name] = data[feature_name].map(freq_encoder)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e10359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_to_digit(df, features):\n",
    "    df = df.copy(deep=True)\n",
    "    for i, feature in enumerate(features):\n",
    "        # feature = str.replace(feature,' ','_')\n",
    "        values_list = df[feature].value_counts()\n",
    "        names = sorted(values_list.index)\n",
    "        # names = sorted(names)\n",
    "        for name in names:\n",
    "            name = str.replace(name,' ','_')\n",
    "            df.insert(3, f'{feature}_{name}', np.where((df[feature]==name),1,0), True)\n",
    "    df.drop(features, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a47b4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perpare_lvl2_1(val_data, train_data, recommender, item_features, user_features, N=50):\n",
    "    # val_data = data_train_lvl_2.copy()\n",
    "    # train_data = data_train_lvl_1.copy()\n",
    "\n",
    "    users_warm = pd.DataFrame(val_data['user_id'].unique()) # Добавим туда еще фитчи user-ов и item-ов.\n",
    "    users_warm.columns = ['user_id']\n",
    "    # Пока только warm start\n",
    "    users_warm = users_warm[users_warm['user_id'].isin(train_data['user_id'].unique())]\n",
    "\n",
    "    users_cold = pd.DataFrame(val_data['user_id'].unique()) # Добавим туда еще фитчи user-ов и item-ов.\n",
    "    users_cold.columns = ['user_id']\n",
    "    # cold_start\n",
    "    users_cold = users_cold[~users_cold['user_id'].isin(users_warm['user_id'].unique())]\n",
    "\n",
    "    # Заполняем кандидатов, на основе предсказания модели 1-го уровня.\n",
    "    users_cold['candidates'] = users_cold['user_id'].apply(lambda x: recommender.get_top_popular(N=N))\n",
    "    s = users_cold.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "    s.name = 'item_id'\n",
    "\n",
    "    # Это кандидаты. (т.е. предпологаемые покупки совершенные на основе предсказаний.)\n",
    "    users_cold = users_cold.drop('candidates', axis=1).join(s)\n",
    "    users_cold['drop'] = 1  # фиктивная переменная\n",
    "    # Заполняем кандидатов, на основе предсказания модели 1-го уровня.\n",
    "    users_warm['candidates'] = users_warm['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=N))\n",
    "    # test_users = data\n",
    "    s = users_warm.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "    s.name = 'item_id'\n",
    "\n",
    "    # Это кандидаты. (т.е. предпологаемые покупки совершенные на основе предсказаний.)\n",
    "    users_warm = users_warm.drop('candidates', axis=1).join(s)\n",
    "    users_warm['drop'] = 1  # фиктивная переменная\n",
    "\n",
    "    # Создадим таблицу с реальными покупками user-ов. \n",
    "    targets = val_data[['user_id', 'item_id']].copy() # свойства \n",
    "    targets['target'] = 1  # тут только покупки\n",
    "\n",
    "    # Объединим предпологаемые покупки с реальными, совершенными user-ами.\n",
    "    targets_cold = users_cold.merge(targets, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "    # В результате, напротив товаров, в редсказании которых мы ошиблись, \n",
    "    # будет стоять Nan. Заполним их  нулями.  \n",
    "    targets_cold['target'].fillna(0, inplace= True)\n",
    "    targets_cold.drop('drop', axis=1, inplace=True)\n",
    "    # Добавим к нашему датасету фичи user-ов и item-ов.\n",
    "    targets_cold = targets_cold.merge(item_features, on='item_id', how='left')\n",
    "    targets_cold = targets_cold.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "    # Объединим предпологаемые покупки с реальными, совершенными user-ами.\n",
    "    targets_warm = users_warm.merge(targets, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "    # В результате, напротив товаров, в редсказании которых мы ошиблись, \n",
    "    # будет стоять Nan. Заполним их  нулями.  \n",
    "    targets_warm['target'].fillna(0, inplace= True)\n",
    "    targets_warm.drop('drop', axis=1, inplace=True)\n",
    "    # targets_warm['target'].mean() #Угадали примерно 17% покупок.\n",
    "\n",
    "    # Добавим к нашему датасету фичи user-ов и item-ов.\n",
    "    targets_warm = targets_warm.merge(item_features, on='item_id', how='left')\n",
    "    targets_warm = targets_warm.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "    targets_lvl_2 = pd.concat([targets_warm, targets_cold], ignore_index=True)\n",
    "\n",
    "    # X_ = targets_lvl_2.drop('target', axis=1)\n",
    "    # y_ = targets_lvl_2[['target']]\n",
    "\n",
    "    return  targets_lvl_2 #X_, y_,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e134a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perpare_lvl2(val_data, train_data, recommender, item_features, user_features, N=50):\n",
    "    users_lvl_2 = pd.DataFrame(val_data['user_id'].unique()) # Добавим туда еще фитчи user-ов и item-ов.\n",
    "    users_lvl_2.columns = ['user_id']\n",
    "\n",
    "    # Пока только warm start\n",
    "    users_lvl_2 = users_lvl_2[users_lvl_2['user_id'].isin(train_data['user_id'].unique())]\n",
    "\n",
    "    # Заполняем кандидатов, на основе предсказания модели 1-го уровня.\n",
    "    users_lvl_2['candidates'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=N))\n",
    "    # test_users = data\n",
    "    s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "    s.name = 'item_id'\n",
    "\n",
    "    # Это кандидаты. (т.е. предпологаемые покупки совершенные на основе предсказаний.)\n",
    "    users_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "    users_lvl_2['drop'] = 1  # фиктивная переменная\n",
    "\n",
    "    # Создадим таблицу с реальными покупками user-ов. \n",
    "    targets_lvl_2 = val_data[['user_id', 'item_id']].copy() # свойства \n",
    "    targets_lvl_2['target'] = 1  # тут только покупки \n",
    "\n",
    "    # Объединим предпологаемые покупки с реальными, совершенными user-ами.\n",
    "    targets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "    # В результате, напротив товаров, в редсказании которых мы ошиблись, \n",
    "    # будет стоять Nan. Заполним их  нулями.  \n",
    "    targets_lvl_2['target'].fillna(0, inplace= True)\n",
    "    targets_lvl_2.drop('drop', axis=1, inplace=True)\n",
    "    targets_lvl_2['target'].mean() #Угадали примерно 17% покупок.\n",
    "\n",
    "    # Добавим к нашему датасету фичи user-ов и item-ов.\n",
    "    targets_lvl_2 = targets_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "    targets_lvl_2 = targets_lvl_2.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "    X_ = targets_lvl_2.drop('target', axis=1)\n",
    "    y_ = targets_lvl_2[['target']]\n",
    "    return X_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "561816e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainRecommender:\n",
    "    \"\"\"Рекоммендации, которые можно получить из ALS\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    user_item_matrix: pd.DataFrame\n",
    "        Матрица взаимодействий user-item\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, weighting=True):\n",
    "        \n",
    "        # Топ покупок каждого юзера\n",
    "        self.top_purchases = data.groupby(['user_id', 'item_id'])['quantity'].count().reset_index()\n",
    "        self.top_purchases.sort_values('quantity', ascending=False, inplace=True) # Это к-во покупок.\n",
    "        self.top_purchases = self.top_purchases[self.top_purchases['item_id'] != 999999] # исключим из ТОП-а покупок item_id = 999999\n",
    "\n",
    "        # Топ покупок по всему датасету\n",
    "        self.overall_top_purchases = data.groupby('item_id')['quantity'].count().reset_index()\n",
    "        self.overall_top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
    "        self.overall_top_purchases = self.overall_top_purchases[self.overall_top_purchases['item_id'] != 999999] # исключим из ТОП-а покупок item_id = 999999\n",
    "        self.overall_top_purchases = self.overall_top_purchases.item_id.tolist()\n",
    "\n",
    "        self.user_item_matrix = self._prepare_matrix(data)  # pd.DataFrame\n",
    "        self.id_to_itemid, self.id_to_userid, \\\n",
    "            self.itemid_to_id, self.userid_to_id = self._prepare_dicts(self.user_item_matrix)\n",
    "\n",
    "        if weighting:\n",
    "            self.user_item_matrix = bm25_weight(self.user_item_matrix.T).T # настроить параметры взвешивния. \n",
    "\n",
    "        self.als_model = self.fit(self.user_item_matrix)\n",
    "        self.own_recommender_model = self.fit_own_recommender(self.user_item_matrix)\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_matrix(data):\n",
    "        \"\"\"Готовит user-item матрицу\"\"\"\n",
    "        user_item_matrix = pd.pivot_table(data,\n",
    "                                          index='user_id', \n",
    "                                          columns='item_id',\n",
    "                                          values='quantity',  # Можно пробовать другие варианты\n",
    "                                          aggfunc='mean',\n",
    "                                          fill_value=0\n",
    "                                          )\n",
    "\n",
    "        user_item_matrix = user_item_matrix.astype(float)  # необходимый тип матрицы для implicit\n",
    "\n",
    "        return user_item_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_dicts(user_item_matrix):\n",
    "        \"\"\"Подготавливает вспомогательные словари\"\"\"\n",
    "\n",
    "        userids = user_item_matrix.index.values\n",
    "        itemids = user_item_matrix.columns.values\n",
    "\n",
    "        matrix_userids = np.arange(len(userids))\n",
    "        matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "        id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "        id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "        itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "        userid_to_id = dict(zip(userids, matrix_userids))\n",
    "\n",
    "        return id_to_itemid, id_to_userid, itemid_to_id, userid_to_id\n",
    "\n",
    "    @staticmethod\n",
    "    def fit_own_recommender(user_item_matrix):\n",
    "        \"\"\"Обучает модель, которая рекомендует товары, среди товаров, купленных юзером\"\"\"\n",
    "\n",
    "        own_recommender = ItemItemRecommender(K=1, num_threads=4)\n",
    "        own_recommender.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "\n",
    "        return own_recommender\n",
    "\n",
    "    @staticmethod\n",
    "    def fit(user_item_matrix, n_factors=30, regularization=0.001, iterations=15, num_threads=4):\n",
    "        \"\"\"Обучает ALS\"\"\"\n",
    "\n",
    "        model = AlternatingLeastSquares(factors=n_factors,\n",
    "                                        regularization=regularization,\n",
    "                                        iterations=iterations,\n",
    "                                        num_threads=num_threads, \n",
    "                                        random_state=0)\n",
    "\n",
    "        model.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "\n",
    "        return model\n",
    "\n",
    "    def _update_dict(self, user_id):\n",
    "        \"\"\"Если появился новыю user / item, то нужно обновить словари\"\"\"\n",
    "\n",
    "        if user_id not in self.userid_to_id.keys():\n",
    "\n",
    "            max_id = max(list(self.userid_to_id.values()))\n",
    "            max_id += 1\n",
    "\n",
    "            self.userid_to_id.update({user_id: max_id})\n",
    "            self.id_to_userid.update({max_id: user_id})\n",
    "\n",
    "    def _get_similar_item(self, item_id):\n",
    "        \"\"\"Находит товар, похожий на item_id\"\"\"\n",
    "        recs = self.als_model.similar_items(self.itemid_to_id[item_id], N=2)  # Товар похож на себя -> рекомендуем 2 товара\n",
    "        top_rec = recs[1][0]  # И берем второй (не товар из аргумента метода)\n",
    "        return self.id_to_itemid[top_rec]\n",
    "\n",
    "    def _extend_with_als(self, user, recommendations, N=5):\n",
    "        \"\"\"Если кол-во рекоммендаций < N, то дополняем их топ-популярными\"\"\"\n",
    "\n",
    "        if len(recommendations) < N:\n",
    "            recommendations.extend(self.get_als_recommendations(user, N))\n",
    "            recommendations = recommendations[:N]\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    def get_top_popular(self, N=5):\n",
    "        \"\"\"Если кол-во рекоммендаций < N, то дополняем их топ-популярными\"\"\"\n",
    "        recommendations = self.overall_top_purchases[:N]\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    def _extend_with_top_popular(self, recommendations, N=5):\n",
    "        \"\"\"Если кол-во рекоммендаций < N, то дополняем их топ-популярными\"\"\"\n",
    "\n",
    "        if len(recommendations) < N:\n",
    "            recommendations.extend(self.overall_top_purchases[:N])\n",
    "            recommendations = recommendations[:N]\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    def _get_recommendations(self, user, model, N=5):\n",
    "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
    "        \n",
    "        self._update_dict(user_id=user)\n",
    "        \n",
    "        recs = model.recommend(userid=self.userid_to_id[user],\n",
    "                                        user_items=csr_matrix(self.user_item_matrix).tocsr(),\n",
    "                                        N=N,\n",
    "                                        filter_already_liked_items=False,\n",
    "                                        filter_items=[self.itemid_to_id[999999]],\n",
    "                                        recalculate_user=True)\n",
    "        \n",
    "        res = [self.id_to_itemid[rec[0]] for rec in recs]\n",
    "\n",
    "        # res = self._extend_with_top_popular(res, N=N)\n",
    "\n",
    "        #assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "\n",
    "    def get_als_recommendations(self, user, N=5):\n",
    "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
    "\n",
    "        self._update_dict(user_id=user)\n",
    "        return self._get_recommendations(user, model=self.als_model, N=N)\n",
    "\n",
    "    def get_own_recommendations(self, user, N=5, extend_with_top_popular=False):\n",
    "        \"\"\"Рекомендуем товары среди тех, которые юзер уже купил\"\"\"\n",
    "\n",
    "        self._update_dict(user_id=user)\n",
    "        recs = self._get_recommendations(user, model=self.own_recommender_model, N=N)\n",
    "        if extend_with_top_popular:\n",
    "                # res = [self.id_to_itemid[rec[0]] for rec in recs]\n",
    "                recs = self._extend_with_top_popular(recs, N=N)\n",
    "        # assert len(recs) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return recs\n",
    "\n",
    "    def get_similar_items_recommendation(self, user, N=5):\n",
    "        \"\"\"Рекомендуем товары, похожие на топ-N купленных юзером товаров\"\"\"\n",
    "\n",
    "        top_users_purchases = self.top_purchases[self.top_purchases['user_id'] == user].head(N)\n",
    "\n",
    "        res = top_users_purchases['item_id'].apply(lambda x: self._get_similar_item(x)).tolist()\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "\n",
    "        # assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "\n",
    "    def get_similar_users_recommendation(self, user, N=5):\n",
    "        \"\"\"Рекомендуем топ-N товаров, среди купленных похожими юзерами\"\"\"\n",
    "        res = []\n",
    "        \n",
    "        # Находим топ-N похожих пользователей\n",
    "        similar_users = self.als_model.similar_users(self.userid_to_id[user], N=N+1)\n",
    "        similar_users = [rec[0] for rec in similar_users]\n",
    "        similar_users = similar_users[1:]   # удалим юзера из запроса\n",
    "\n",
    "        for user in similar_users:\n",
    "            userid = self.id_to_userid[user] #own recommender works with user_ids\n",
    "            res.extend(self.get_own_recommendations(userid, N=1))\n",
    "\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "\n",
    "        # assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1948969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a669ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import ItemItemRecommender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "814a4e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/1/Downloads/retail_train.csv')\n",
    "item_features = pd.read_csv('C:/Users/1/Downloads/product.csv')\n",
    "user_features = pd.read_csv('C:/Users/1/Downloads/hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "929f1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 150 # к-во товаров получаемых из модели 1-го уровня.\n",
    "final_predict_count = 30 # К-во рекомендаций выдаваемых\n",
    "val_count = 5 # финальное к-во репомендаций товаров. На них будет осуществляться подсчет к-ва.\n",
    "top_items_count = 5000 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a0f15a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1036325</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "2     2375  26984851472    1  1036325         1         0.99       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  \n",
       "2         -0.3        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28779da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FRZN ICE</td>\n",
       "      <td>ICE - CRUSHED/CUBED</td>\n",
       "      <td>22 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26081</td>\n",
       "      <td>2</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26093</td>\n",
       "      <td>69</td>\n",
       "      <td>PASTRY</td>\n",
       "      <td>Private</td>\n",
       "      <td>BREAD</td>\n",
       "      <td>BREAD:ITALIAN/FRENCH</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  manufacturer    department     brand            commodity_desc  \\\n",
       "0    25671             2       GROCERY  National                  FRZN ICE   \n",
       "1    26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n",
       "2    26093            69        PASTRY   Private                     BREAD   \n",
       "\n",
       "            sub_commodity_desc curr_size_of_product  \n",
       "0          ICE - CRUSHED/CUBED                22 LB  \n",
       "1  NO SUBCOMMODITY DESCRIPTION                       \n",
       "2         BREAD:ITALIAN/FRENCH                       "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "494c7918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45-54</td>\n",
       "      <td>A</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-34</td>\n",
       "      <td>U</td>\n",
       "      <td>25-34K</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2 Adults Kids</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_desc marital_status_code income_desc homeowner_desc      hh_comp_desc  \\\n",
       "0      65+                   A      35-49K      Homeowner  2 Adults No Kids   \n",
       "1    45-54                   A      50-74K      Homeowner  2 Adults No Kids   \n",
       "2    25-34                   U      25-34K        Unknown     2 Adults Kids   \n",
       "\n",
       "  household_size_desc kid_category_desc  user_id  \n",
       "0                   2      None/Unknown        1  \n",
       "1                   2      None/Unknown        7  \n",
       "2                   3                 1        8  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a4ad25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_day = {'week_day': []}\n",
    "# считаем номер недели. поле чего вычисляем записи с номеро дня. \n",
    "# определяем номер дня соответствуующий номеру последнему дню недели и после этого начинаем вычетать из него.\n",
    "# номера номера дней. \n",
    "max_week_no = data['week_no'].max()\n",
    "min_week_no = data['week_no'].min()\n",
    "\n",
    "week_days=[]\n",
    "for week_no in range(min_week_no,max_week_no + 1):\n",
    "    max_day_in_week = data.loc[(data['week_no']==week_no),'day'].max()\n",
    "    days = data.loc[(data['week_no']==week_no),'day']\n",
    "    for day in days:\n",
    "        week_days.append(day-max_day_in_week+7)\n",
    "\n",
    "data['week_day'] = week_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba9df365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "      <th>week_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  week_day  \n",
       "0         -0.6        1631        1          0.0                0.0         3  \n",
       "1          0.0        1631        1          0.0                0.0         3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cхема обучения и валидации!\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
    "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
    "\n",
    "val_lvl_1_size_weeks = 6\n",
    "val_lvl_2_size_weeks = 3\n",
    "\n",
    "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
    "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
    "\n",
    "data_train_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ade9fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 83685 to 5001\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, item_features=item_features, take_n_popular=top_items_count)\n",
    "\n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ebc0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_values(old_df, new_df,feature):\n",
    "    old_values = old_df[feature].unique()\n",
    "    new_values = new_df[feature].unique()\n",
    "    appended_values = []\n",
    "\n",
    "    for value  in new_values: \n",
    "        if value not in old_values:\n",
    "            appended_values.append(value)\n",
    "        \n",
    "    appended_values = np.unique(appended_values)\n",
    "    return appended_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a99bc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изначальное к-во: users: 2299, items: 5001\n",
      "1-й уровень  users: +70, items: +22772\n",
      "2-й уровень  users: +74, items: +19567\n"
     ]
    }
   ],
   "source": [
    "first_users_count = len(data_train_lvl_1['user_id'].unique()) \n",
    "first_items_count = len(data_train_lvl_1['item_id'].unique()) \n",
    "\n",
    "new_user_lvl_1 = get_new_values(data_train_lvl_1, data_train_lvl_2 ,'user_id')\n",
    "new_items_lvl_1 = get_new_values(data_train_lvl_1, data_train_lvl_2 ,'item_id')\n",
    "\n",
    "new_user_lvl_2 = get_new_values(data_train_lvl_1, data_val_lvl_2 ,'user_id')\n",
    "new_items_lvl_2 = get_new_values(data_train_lvl_1, data_val_lvl_2 ,'item_id')\n",
    "\n",
    "print(f'Изначальное к-во: users: {first_users_count}, items: {first_items_count}')\n",
    "print(f'1-й уровень  users: +{len(new_user_lvl_1)}, items: +{len(new_items_lvl_1)}')\n",
    "print(f'2-й уровень  users: +{len(new_user_lvl_2)}, items: +{len(new_items_lvl_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98772f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gr = data.groupby('basket_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c65befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднее к-во покупаемых товаров.\n",
    "user_features['median_quantity'] = user_features['user_id'].apply(lambda x: \n",
    "                                data_gr.loc[(data_gr['user_id']==x),'quantity'].median())\n",
    "\n",
    "# Средний чек.                                \n",
    "user_features['mean_sales_value'] = user_features['user_id'].apply(lambda x: \n",
    "                                data_gr.loc[(data_gr['user_id']==x),'sales_value'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "911d9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Среднее к-во раз в неделю, которое user ходит в магазин.\n",
    "\n",
    "for i in [1,2,3,4,5,6,7]:\n",
    "    data_gr[f\"day_{i}\"] = np.where((data_gr['week_day'] == i),1,0)\n",
    "    \n",
    "week_count = data['week_no'].max()\n",
    "#-----------------------------------------------\n",
    "def mean_quantity_in_week(user_id):\n",
    "    days = 0\n",
    "    for i in [1,2,3,4,5,6,7]:\n",
    "       days += data_gr.loc[(data_gr['user_id']==user_id),f'day_{i}'].sum()\n",
    "    days /=week_count\n",
    "    return int(np.round(days))\n",
    "\n",
    "#-----------------------------------------------    \n",
    "user_features['mean_quantity_in_week'] = user_features['user_id'].apply(lambda x: mean_quantity_in_week(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d102f671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "      <th>user_id</th>\n",
       "      <th>median_quantity</th>\n",
       "      <th>mean_sales_value</th>\n",
       "      <th>mean_quantity_in_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2.726818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45-54</td>\n",
       "      <td>A</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>7</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>2.989986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_desc marital_status_code income_desc homeowner_desc      hh_comp_desc  \\\n",
       "0      65+                   A      35-49K      Homeowner  2 Adults No Kids   \n",
       "1    45-54                   A      50-74K      Homeowner  2 Adults No Kids   \n",
       "\n",
       "  household_size_desc kid_category_desc  user_id  median_quantity  \\\n",
       "0                   2      None/Unknown        1         1.100000   \n",
       "1                   2      None/Unknown        7         1.181818   \n",
       "\n",
       "   mean_sales_value  mean_quantity_in_week  \n",
       "0          2.726818                      1  \n",
       "1          2.989986                      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79ef4c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income_desc\n",
      "['35-49K' '50-74K' '25-34K' '75-99K' 'Under 15K' '100-124K' '15-24K'\n",
      " '125-149K' '150-174K' '250K+' '175-199K' '200-249K']\n",
      "--------------------\n",
      "age_desc\n",
      "['65+' '45-54' '25-34' '35-44' '19-24' '55-64']\n",
      "--------------------\n",
      "homeowner_desc\n",
      "['Homeowner' 'Unknown' 'Renter' 'Probable Renter' 'Probable Owner']\n",
      "--------------------\n",
      "kid_category_desc\n",
      "['None/Unknown' '1' '2' '3+']\n",
      "--------------------\n",
      "household_size_desc\n",
      "['2' '3' '4' '1' '5+']\n",
      "--------------------\n",
      "hh_comp_desc\n",
      "['2 Adults No Kids' '2 Adults Kids' 'Single Female' 'Unknown'\n",
      " 'Single Male' '1 Adult Kids']\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "### Список категориальных фитчей ктороые мы будем разбирать.\n",
    "features=['income_desc','age_desc','homeowner_desc','kid_category_desc','household_size_desc','hh_comp_desc']\n",
    "for feature_name in features:\n",
    "    print(feature_name)\n",
    "    print(user_features[feature_name].unique())\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fac9495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_desc = {'35-49K':42, '50-74K':62, '25-34K':30, '75-99K':87, 'Under 15K':15, '100-124K':112,\n",
    "       '15-24K':20, '125-149K':137, '150-174K':162, '250K+':250, '175-199K':187, '200-249K':225}\n",
    "       \n",
    "user_features['income_desc'] = user_features['income_desc'].apply(lambda x: income_desc[x]) \n",
    "\n",
    "age_desc = {'65+':65, '45-54':50, '25-34':30, '35-44':40, '19-24':21, '55-64':60}\t\n",
    "\n",
    "user_features['age_desc'] = user_features['age_desc'].apply(lambda x: age_desc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ef3482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "household_size_desc = {np.nan: 0, '1':1, '2':2, '3':3, '4':4, '5+':5 }\n",
    "\n",
    "user_features['household_size_desc'] = user_features['household_size_desc'].apply(lambda x: household_size_desc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14375332",
   "metadata": {},
   "outputs": [],
   "source": [
    "kid_category_desc = {'None/Unknown':0, np.nan: 0, '1':1, '2':2, '3+':3 }\n",
    "\n",
    "user_features['kid_category_desc'] = user_features['kid_category_desc'].apply(lambda x: kid_category_desc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5bf53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features[['hh_comp_desc_female', 'hh_comp_desc_male', 'hh_comp_desc_Adults_Kids']] = 0\n",
    "user_features['hh_comp_desc_female'] = np.where((user_features['hh_comp_desc'] !='Single Male'), 1, 0)\n",
    "user_features['hh_comp_desc_male'] = np.where((user_features['hh_comp_desc'] !='Single Female'), 1, 0)\n",
    "user_features.loc[(user_features['hh_comp_desc']=='2 Adults Kids'), 'hh_comp_desc_Adults_Kids'] = 2\n",
    "user_features.loc[(user_features['hh_comp_desc']=='1 Adult Kids'), 'hh_comp_desc_Adults_Kids'] = 1\n",
    "user_features.loc[(user_features['hh_comp_desc'].isna()), ['hh_comp_desc_female','hh_comp_desc_male']] = 0\n",
    "user_features.loc[(user_features['hh_comp_desc']=='Unknown'), ['hh_comp_desc_female','hh_comp_desc_male']] = 0\n",
    "user_features.drop('hh_comp_desc', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ca6d9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "      <th>user_id</th>\n",
       "      <th>median_quantity</th>\n",
       "      <th>mean_sales_value</th>\n",
       "      <th>mean_quantity_in_week</th>\n",
       "      <th>hh_comp_desc_female</th>\n",
       "      <th>hh_comp_desc_male</th>\n",
       "      <th>hh_comp_desc_Adults_Kids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>A</td>\n",
       "      <td>42</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2.726818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>A</td>\n",
       "      <td>62</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>2.989986</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_desc marital_status_code  income_desc homeowner_desc  \\\n",
       "0        65                   A           42      Homeowner   \n",
       "1        50                   A           62      Homeowner   \n",
       "\n",
       "   household_size_desc  kid_category_desc  user_id  median_quantity  \\\n",
       "0                    2                  0        1         1.100000   \n",
       "1                    2                  0        7         1.181818   \n",
       "\n",
       "   mean_sales_value  mean_quantity_in_week  hh_comp_desc_female  \\\n",
       "0          2.726818                      1                    1   \n",
       "1          2.989986                      1                    1   \n",
       "\n",
       "   hh_comp_desc_male  hh_comp_desc_Adults_Kids  \n",
       "0                  1                         0  \n",
       "1                  1                         0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35c0834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FRZN ICE</td>\n",
       "      <td>ICE - CRUSHED/CUBED</td>\n",
       "      <td>22 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26081</td>\n",
       "      <td>2</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  manufacturer    department     brand            commodity_desc  \\\n",
       "0    25671             2       GROCERY  National                  FRZN ICE   \n",
       "1    26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n",
       "\n",
       "            sub_commodity_desc curr_size_of_product  \n",
       "0          ICE - CRUSHED/CUBED                22 LB  \n",
       "1  NO SUBCOMMODITY DESCRIPTION                       "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a3ff4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features_temp = item_features.merge(data, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3e47d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость товара в категории.\n",
    "\n",
    "item_price = item_features_temp.groupby(['item_id','commodity_desc'])['sales_value'].mean().reset_index()\n",
    "item_price.columns= ['item_id','commodity_desc','sales_value']\n",
    "commoditys_desc = item_price['commodity_desc'].unique()\n",
    "\n",
    "item_price['commodity_desc_mean_sale']=np.NaN\n",
    "\n",
    "for commodity_desc in commoditys_desc:\n",
    "    mean_value = item_price.loc[(item_price['commodity_desc']==commodity_desc),'sales_value'].mean()\n",
    "    item_price.loc[(item_price['commodity_desc']==commodity_desc),'commodity_desc_mean_sale'] = mean_value\n",
    "\n",
    "item_price.loc[(item_price['commodity_desc']=='NO COMMODITY DESCRIPTION'),'sales_value']\n",
    "\n",
    "item_features = item_features.merge(item_price[['item_id','commodity_desc_mean_sale']], on='item_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "911baac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# К-во покупок в неделю.\n",
    "quantity_count = item_features_temp.groupby(['item_id'])['quantity'].sum().reset_index()\n",
    "\n",
    "quantity_count.columns = ['item_id','quantity']\n",
    "\n",
    "quantity_in_week = item_features_temp.groupby(['item_id'])['week_no'].unique().reset_index()\n",
    "\n",
    "quantity_in_week.columns = ['item_id','weeks']\n",
    "\n",
    "quantity_in_week['weeks_count'] = quantity_in_week['weeks'].apply(lambda x: len(x))\n",
    "\n",
    "quantity_in_week['sale_in_week'] = quantity_count['quantity']/quantity_in_week['weeks_count']  \n",
    "\n",
    "item_features = item_features.merge(quantity_in_week[['item_id','sale_in_week']], on='item_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9212ec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\anaconda3\\lib\\site-packages\\implicit\\utils.py:28: UserWarning: OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70961ac8dc4d49419093337125b0cc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22406887edda471e8171f25088a56a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommender = MainRecommender(data_train_lvl_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = perpare_lvl2_1(data_train_lvl_2, data_train_lvl_1, recommender,item_features, user_features, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f80e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = perpare_lvl2_1(data_val_lvl_2, data_train_lvl_1, recommender, item_features, user_features, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим список катероиальных и числовых признаков.\n",
    "categorical = []\n",
    "numerical = []\n",
    "for col, value in train_data.iteritems():\n",
    "    if value.dtype == 'object':\n",
    "        categorical.append(col)\n",
    "    else:\n",
    "        numerical.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fd947",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical:\n",
    "print(f'{feature}: {len(train_data[feature].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf9c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['commodity_desc', 'sub_commodity_desc', 'curr_size_of_product']\n",
    "train_data = train_data.drop(features, axis=1)\n",
    "test_data = test_data.drop(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['department'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e91647",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'department',\n",
    "            'brand',\n",
    "            #'commodity_desc',\n",
    "            #'sub_commodity_desc',\n",
    "            #'curr_size_of_product',\n",
    "            'marital_status_code',\n",
    "            'homeowner_desc',\n",
    "            # 'hh_comp_desc',\n",
    "            # 'household_size_desc',\n",
    "            # 'kid_category_desc'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c44467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = category_to_digit(train_data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52736a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = category_to_digit(test_data, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afebedf3",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = Task('binary', loss='logloss', metric='auc', greater_is_better=False)\n",
    "TIMEOUT = 300000\n",
    "N_THREADS = 4\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 27\n",
    "TARGET_NAME = 'target'\n",
    "TEST_SIZE=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'target': TARGET_NAME, 'drop': ['user_id', 'item_id']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_model = TabularAutoML(task=TASK,\n",
    "                            timeout=TIMEOUT,\n",
    "                            cpu_limit = N_THREADS,\n",
    "                            # gpu_ids='all',\n",
    "                            reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                             \n",
    "                            general_params={'use_algos': [ ['lgb_tuned', 'cb_tuned'] ]},\n",
    "                             \n",
    "                            tuning_params={'max_tuning_iter': 10},\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = automl_model.fit_predict(train_data, roles = roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = train_preds.data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ccc7a",
   "metadata": {},
   "source": [
    "### Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177689c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(x_data, items, user_id, item_name, N=5, overall_top_purchases=None):\n",
    "    items_list = []\n",
    " \n",
    "    for item in items:\n",
    "        flag = (x_data.loc[((x_data['user_id']==user_id) & (x_data['item_id']==item)),item_name].mean())\n",
    "        \n",
    "        if (flag > 0.3):\n",
    "            items_list.append(item)\n",
    "\n",
    "    if not(overall_top_purchases is None):\n",
    "\n",
    "        if len(items_list) < N:\n",
    "            items_list.extend(overall_top_purchases[:N])\n",
    "        items_list = items_list[:N]\n",
    "    return items_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_recomendations(x_data, y_data, preds):\n",
    "    x_data = x_data.copy()\n",
    "    x_data['predict'] = preds\n",
    "    x_data['actual'] = y_data['target'].values\n",
    "\n",
    "    result = x_data.sort_values('predict', ascending=False).groupby('user_id')['item_id'].unique().reset_index()\n",
    "\n",
    "    overall_top_purchases = x_data.groupby('item_id')['item_id'].count()\n",
    "    overall_top_purchases = overall_top_purchases.sort_values(ascending=False).index.values\n",
    "\n",
    "    result_df= {'user_id':[], 'actual':[], 'predict':[]}\n",
    "\n",
    "    for res in tqdm(result.iterrows()):\n",
    "        user_id = res[1]['user_id']\n",
    "        item_ids = res[1]['item_id']\n",
    "        actual = get_items(x_data, item_ids, user_id, 'actual', N=final_predict_count)\n",
    "        if len(actual)>0:\n",
    "            result_df['user_id'].append(user_id)\n",
    "            predict_items= get_items(x_data, item_ids, user_id, 'predict', N=final_predict_count, overall_top_purchases = overall_top_purchases)\n",
    "            result_df['predict'].append(postfilter_items(predict_items, item_features, N=val_count)) # Бизнес-ограничения. ^_^\n",
    "            result_df['actual'].append(actual)\n",
    "    return pd.DataFrame(result_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('target', axis=1)\n",
    "y_train = train_data[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43885f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = get_final_recomendations(X_train, y_train, train_preds)\n",
    "\n",
    "result_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a1f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_train = result_train.apply(lambda row: precision_at_k(row['predict'], row['actual']), axis=1).mean()\n",
    "print(f'Train precision: {precision_train:.03}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = automl_model.predict(test_data).data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510053f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = get_final_recomendations(X_test, y_test, test_preds)\n",
    "\n",
    "result_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e06238",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test = result_test.apply(lambda row: precision_at_k(row['predict'], row['actual']), axis=1).mean()\n",
    "print(f'Test precision: {precision_test:.03}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test.to_csv('finally_prediction_lama_classifaer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9318c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('automl_model_classifaer.pickle', 'wb') as f:\n",
    "    pickle.dump(automl_model, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68f1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
